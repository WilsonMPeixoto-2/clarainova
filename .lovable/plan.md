
# Plano: Busca Web Robusta ‚Äî "Consulta com Evid√™ncia"

## Diagn√≥stico Confirmado

### Arquitetura Atual
A CLARA usa **Google Search Grounding nativo do Gemini SDK**:
```
Query ‚Üí RAG insuficiente? ‚Üí modelOptions.tools = [{ googleSearch: {} }]
                                    ‚Üì
                          Gemini recebe query + grounding
                                    ‚Üì
                          Resposta com groundingMetadata (snippets)
```

### Problemas Identificados
| Problema | Impacto | Causa Raiz |
|----------|---------|------------|
| Confunde SEI Rio com Processo.Rio | Alto | Resposta baseada em snippet SERP, sem ler a p√°gina |
| Links incorretos | Alto | Grounding retorna URL do snippet, n√£o valida conte√∫do |
| Sem evid√™ncia cit√°vel | M√©dio | Apenas "title - url", sem trecho exato |
| 1 fonte = alto risco | Alto | Sem qu√≥rum de valida√ß√£o cruzada |
| Custo descontrolado | M√©dio | Sem cache, toda query gasta API |

---

## Solu√ß√£o Proposta

### Nova Arquitetura: Fetch + Validate

```text
Query ‚Üí RAG Local (pgvector)
              ‚Üì
  Se < 3 chunks OU avgScore < 0.015
              ‚Üì
  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
  ‚îÇ    WEB SEARCH ENGINE           ‚îÇ
  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
  ‚îÇ  ‚îÇ 1. Check Cache (24h)     ‚îÇ  ‚îÇ
  ‚îÇ  ‚îÇ 2. Buscar SERP (6-10)    ‚îÇ  ‚îÇ
  ‚îÇ  ‚îÇ 3. Fetch HTML/PDF        ‚îÇ  ‚îÇ
  ‚îÇ  ‚îÇ 4. Extrair texto         ‚îÇ  ‚îÇ
  ‚îÇ  ‚îÇ 5. Classificar dom√≠nio   ‚îÇ  ‚îÇ
  ‚îÇ  ‚îÇ 6. Validar qu√≥rum        ‚îÇ  ‚îÇ
  ‚îÇ  ‚îÇ 7. Extrair excerpts      ‚îÇ  ‚îÇ
  ‚îÇ  ‚îÇ 8. Salvar cache          ‚îÇ  ‚îÇ
  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚Üì
  Contexto enriquecido com evid√™ncias
              ‚Üì
  Gemini + prompt com cita√ß√µes obrigat√≥rias
```

---

## Parte 1: Infraestrutura de Cache e Dom√≠nios

### 1.1 Nova Tabela: `web_search_cache`
```sql
CREATE TABLE web_search_cache (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  query_hash TEXT NOT NULL,  -- SHA256 da query normalizada
  query_text TEXT NOT NULL,
  
  -- Resultados SERP
  serp_results JSONB NOT NULL,  -- [{url, title, snippet}]
  
  -- Conte√∫do extra√≠do
  fetched_pages JSONB NOT NULL,  -- [{url, title, content, excerpt_used, confidence}]
  
  -- Metadados
  created_at TIMESTAMPTZ DEFAULT now(),
  expires_at TIMESTAMPTZ DEFAULT (now() + INTERVAL '24 hours'),
  hit_count INTEGER DEFAULT 0,
  
  -- Indexa√ß√£o
  UNIQUE(query_hash)
);

CREATE INDEX idx_cache_query_hash ON web_search_cache(query_hash);
CREATE INDEX idx_cache_expires ON web_search_cache(expires_at);
```

### 1.2 Nova Tabela: `trusted_domains`
```sql
CREATE TABLE trusted_domains (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  domain TEXT NOT NULL UNIQUE,
  category TEXT NOT NULL,  -- 'primary', 'official_mirror', 'aggregator'
  priority INTEGER DEFAULT 50,  -- 100 = m√°xima, 1 = m√≠nima
  description TEXT,
  created_at TIMESTAMPTZ DEFAULT now()
);

-- Inserir dom√≠nios iniciais
INSERT INTO trusted_domains (domain, category, priority, description) VALUES
  ('doweb.rio.rj.gov.br', 'primary', 100, 'Di√°rio Oficial do Munic√≠pio - espelho oficial'),
  ('prefeitura.rio', 'primary', 95, 'Portal oficial Prefeitura Rio'),
  ('rio.rj.gov.br', 'primary', 95, 'Dom√≠nio oficial governo Rio'),
  ('gov.br', 'primary', 90, 'Portais federais/estaduais'),
  ('tcm.rj.gov.br', 'primary', 85, 'Tribunal de Contas do Munic√≠pio'),
  ('camara.rj.gov.br', 'primary', 80, 'C√¢mara Municipal'),
  ('leismunicipais.com.br', 'aggregator', 60, 'Consolidador - √∫til mas secund√°rio'),
  ('jusbrasil.com.br', 'aggregator', 40, 'Refer√™ncia mas preferir fontes oficiais');
```

---

## Parte 2: Edge Function de Web Search

### 2.1 Nova Fun√ß√£o: `web-search/index.ts`

Responsabilidades:
- Consultar cache antes de buscar
- Usar Google Custom Search API (ou fetch nativo com parsing)
- Fazer HTTP GET nos top N URLs
- Extrair texto (HTML ‚Üí Markdown limpo)
- Classificar por dom√≠nio e calcular confian√ßa
- Retornar com excerpts cit√°veis

### 2.2 Par√¢metros de Controle (Web Quick vs Deep)

| Modo | Resultados SERP | P√°ginas Fetch | Cross-check | Uso |
|------|-----------------|---------------|-------------|-----|
| `quick` | 5 | 3 | N√£o | D√∫vidas simples |
| `deep` | 10 | 6 | Sim (2+ fontes) | Prazos, artigos, obriga√ß√µes |

### 2.3 Estrutura de Resposta

```typescript
interface WebSearchResult {
  query: string;
  mode: 'quick' | 'deep';
  cached: boolean;
  sources: {
    url: string;
    title: string;
    domain: string;
    domain_category: 'primary' | 'official_mirror' | 'aggregator';
    priority: number;
    excerpt_used: string;  // 2-6 linhas
    confidence: 'high' | 'medium' | 'low';
    retrieved_at: string;
  }[];
  quorum_met: boolean;  // true se 2+ fontes independentes
  context_for_llm: string;  // Texto consolidado para o prompt
}
```

---

## Parte 3: Integra√ß√£o no clara-chat

### 3.1 Fluxo Atualizado

```typescript
// Determinar se precisa web search
const needsWebSearch = 
  finalChunks.length < 3 || avgTopScore < 0.015;

if (needsWebSearch) {
  // Determinar modo baseado no tipo de query
  const webMode = isNormativeQuery(message) ? 'deep' : 'quick';
  
  // Chamar web search engine
  const webResults = await callWebSearch(message, webMode);
  
  // Validar qu√≥rum para queries normativas
  if (isNormativeQuery(message) && !webResults.quorum_met) {
    // Emitir notice de baixa confian√ßa
    controller.enqueue(encoder.encode(
      `event: notice\ndata: ${JSON.stringify({ 
        type: "limited_base", 
        message: "Encontrei apenas 1 fonte. Recomendo confirmar na fonte oficial." 
      })}\n\n`
    ));
  }
  
  // Adicionar contexto web ao prompt
  context += webResults.context_for_llm;
  webSources = webResults.sources;
}
```

### 3.2 Detector de Query Normativa

```typescript
function isNormativeQuery(query: string): boolean {
  const patterns = [
    /prazo|dias √∫teis|dias corridos/i,
    /decreto|lei|resolu√ß√£o|portaria|instru√ß√£o normativa/i,
    /artigo|art\.|¬ß|par√°grafo/i,
    /obriga√ß√£o|vedado|proibido|permitido/i,
    /penalidade|multa|san√ß√£o/i,
    /compet√™ncia|atribui√ß√£o/i
  ];
  return patterns.some(p => p.test(query));
}
```

### 3.3 Prompt Atualizado com Regras de Cita√ß√£o

Adicionar ao system prompt:
```
## Regras de Cita√ß√£o Web (OBRIGAT√ìRIO quando usar fontes externas)

1. **Cite com trecho:** Para afirma√ß√µes normativas (prazo, artigo, obriga√ß√£o), COPIE o trecho exato da fonte:
   > "O prazo para recurso √© de 10 (dez) dias √∫teis..." - [Decreto n¬∫ X, doweb.rio.rj.gov.br]

2. **Indique confian√ßa:**
   - üü¢ Alta: 2+ fontes oficiais concordam
   - üü° M√©dia: 1 fonte oficial
   - üî¥ Baixa: apenas agregadores/blogs

3. **Qu√≥rum normativo:** Para prazos, artigos e obriga√ß√µes, busque confirma√ß√£o em 2 fontes independentes.

4. **N√£o infira:** Se a fonte n√£o disser explicitamente, use o template de lacuna.
```

---

## Parte 4: UI de Fontes Premium

### 4.1 Chip de Fonte Atualizado

J√° temos `.source-chip-web`, agora adicionar:
- Badge de categoria (Oficial, Espelho, Agregador)
- Badge de confian√ßa (Alta/M√©dia/Baixa)
- Tooltip com excerpt usado
- Data de recupera√ß√£o

### 4.2 Componente: `SourceChipWeb.tsx`

```tsx
interface WebSource {
  url: string;
  title: string;
  domain_category: 'primary' | 'official_mirror' | 'aggregator';
  confidence: 'high' | 'medium' | 'low';
  excerpt_used: string;
  retrieved_at: string;
}

// Renderiza√ß√£o com tooltip expand√≠vel mostrando o trecho
```

---

## Parte 5: Extra√ß√£o de Conte√∫do

### 5.1 Estrat√©gia de Fetch

Como n√£o temos Firecrawl configurado, usar fetch nativo:

```typescript
async function fetchPageContent(url: string): Promise<string | null> {
  try {
    const response = await fetch(url, {
      headers: {
        'User-Agent': 'CLARA-Bot/1.0 (Assistente Administrativo)'
      },
      signal: AbortSignal.timeout(5000)  // 5s timeout
    });
    
    if (!response.ok) return null;
    
    const html = await response.text();
    return extractTextFromHtml(html);
  } catch {
    return null;
  }
}

function extractTextFromHtml(html: string): string {
  // Remover scripts, styles, nav, footer, header
  // Manter apenas conte√∫do principal
  // Converter para texto limpo
}
```

### 5.2 Limita√ß√µes Conhecidas

- PDFs: precisam de parser adicional (j√° temos pdfjs-serverless no import_map)
- SPAs: n√£o conseguiremos conte√∫do din√¢mico
- Sites com JS pesado: fallback para snippet SERP

---

## Arquivos a Criar/Modificar

| Arquivo | A√ß√£o | Descri√ß√£o |
|---------|------|-----------|
| `supabase/migrations/xxx_web_search_cache.sql` | Criar | Tabelas de cache e dom√≠nios |
| `supabase/functions/web-search/index.ts` | Criar | Engine de busca com fetch |
| `supabase/functions/clara-chat/index.ts` | Modificar | Integrar web-search |
| `src/components/chat/SourceChipWeb.tsx` | Criar | Chip premium com evid√™ncia |
| `src/components/chat/ChatMessage.tsx` | Modificar | Usar novo SourceChipWeb |
| `src/hooks/useChat.ts` | Modificar | Tipos para novos campos de fonte |

---

## Op√ß√£o: Firecrawl Connector

Se voc√™ quiser uma solu√ß√£o mais robusta (JS rendering, melhor extra√ß√£o), posso:
1. Solicitar conex√£o do Firecrawl Connector
2. Implementar usando a API do Firecrawl para scrape

**Vantagens do Firecrawl:**
- Renderiza JavaScript
- Extrai markdown limpo
- Suporta PDFs nativamente
- Mais confi√°vel que fetch simples

**Desvantagens:**
- Custo adicional por request
- Depend√™ncia externa

---

## Ordem de Execu√ß√£o

1. Criar migra√ß√£o para tabelas de cache e dom√≠nios
2. Criar edge function `web-search` com fetch nativo
3. Atualizar `clara-chat` para usar nova engine
4. Criar componente `SourceChipWeb` com evid√™ncia
5. Atualizar UI do chat
6. Testar com queries normativas

---

## Resultado Esperado

1. **Busca web com evid√™ncia:** Cada afirma√ß√£o normativa ter√° trecho cit√°vel
2. **Qu√≥rum de fontes:** 2+ fontes para prazos e obriga√ß√µes
3. **Classifica√ß√£o de dom√≠nios:** Prioridade para fontes oficiais
4. **Cache 24h:** Redu√ß√£o de 80%+ nas chamadas de API para queries repetidas
5. **Transpar√™ncia:** Usu√°rio v√™ "por que" aquela fonte foi usada
6. **Menos alucina√ß√£o:** Sem trecho = template de lacuna, n√£o infer√™ncia

---

## Pergunta Antes de Implementar

Voc√™ prefere:
- **A) Fetch nativo** (mais simples, funciona na maioria dos casos)
- **B) Firecrawl Connector** (mais robusto, requer configura√ß√£o e tem custo)

E sobre o modo Web Quick/Deep:
- **A) Autom√°tico** (baseado em detec√ß√£o de query normativa)
- **B) Toggle no chat** (usu√°rio escolhe)
- **C) Combinado** (autom√°tico com override opcional)
